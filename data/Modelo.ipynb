{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ic-feplEM8MZ",
        "outputId": "7baf78d9-ff9b-4814-ee91-118f47bb27f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator MultinomialNB from version 1.6.0 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator CountVectorizer from version 1.6.0 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "import pickle\n",
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "model = pickle.load(open('model.pkl', 'rb'))\n",
        "vectorizer = pickle.load(open('vectorizer.pkl', 'rb'))\n",
        "\n",
        "def clean_text(text):\n",
        "  text = text.lower()\n",
        "  text = text.replace('\\n', ' ')\n",
        "  stop_words = set(stopwords.words('spanish'))\n",
        "  stop_words.update(['.', ',', '!', '?', ';', ':', '-', '_', '(', ')', '[', ']', '{', '}', '\"', \"'\", '...', '``', \"''\"])\n",
        "  text = ' '.join([word for word in word_tokenize(text) if not word in stop_words])\n",
        "  return text\n",
        "\n",
        "df = pd.read_csv('lyrics.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df['Lyrics'].apply(clean_text)\n",
        "y = df['Regueton']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "dtv = vectorizer.fit_transform(X_train.to_list())\n",
        "model.fit(dtv.toarray(), y_train)\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "y_pred = model.predict(vectorizer.transform(X_test.to_list()).toarray())\n",
        "print(accuracy_score(y_test, y_pred))\n",
        "print(f1_score(y_test, y_pred))\n",
        "confusion_matrix(y_test, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVgb2DC_NikA",
        "outputId": "1cabe308-eb1d-4640-8d90-3fe9d0fdc150"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8152173913043478\n",
            "0.8172043010752689\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[111,  27],\n",
              "       [ 24, 114]])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    }
  ]
}